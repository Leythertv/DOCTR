# DOCTR - OCR Pipeline Multicapa con IA

[![Python](https://img.shields.io/badge/Python-3.7%2B-blue.svg)](https://python.org)
[![Ollama](https://img.shields.io/badge/Ollama-Supported-orange.svg)](https://ollama.ai)

## üöÄ Descripci√≥n General

DOCTR es un avanzado sistema de Reconocimiento √ìptico de Caracteres (OCR) que utiliza un enfoque multicapa para lograr resultados superiores. Combina el poder de la librer√≠a **docTR** con modelos de visi√≥n (VLM) como **Qwen2.5-VL** para proporcionar extracci√≥n de texto precisa y mejorada.

## üèóÔ∏è Arquitectura del Sistema

El pipeline funciona en tres capas principales:

### 1. **Capa de OCR Tradicional**
- Utiliza **docTR** para extracci√≥n inicial de texto
- Soporta m√∫ltiples formatos: PDF, JPG, PNG, y otros formatos de imagen
- Proporciona m√©tricas de confianza para cada palabra detectada

### 2. **Capa de Mejora con IA (VLM)**
- Integra modelos de visi√≥n como **Qwen2.5-VL** a trav√©s de Ollama
- Compara visualmente la imagen original con el texto extra√≠do por OCR
- Corrige errores de reconocimiento bas√°ndose en el an√°lisis visual

### 3. **Capa de Post-procesamiento**
- Limpia y estructura los resultados seg√∫n el tipo de tarea
- Ofrece m√∫ltiples formatos de salida: texto limpio, JSON estructurado, markdown

## ‚ú® Caracter√≠sticas Principales

- üîÑ **Procesamiento Multiformato**: Soporta m√∫ltiples formatos de imagen (JPG, PNG, etc.)
- üß† **Mejora con IA**: Utiliza VLMs para corregir errores del OCR tradicional
- üìä **M√∫ltiples Modos de Salida**: Texto limpio, JSON estructurado, res√∫menes en markdown
- üéØ **Alta Precisi√≥n**: Combinaci√≥n de OCR tradicional + an√°lisis visual
- üîß **Configurable**: F√°cilmente adaptable a diferentes modelos VLM
- üìà **M√©tricas de Confianza**: Evaluaci√≥n de la calidad del reconocimiento
- üíæ **Guardado Autom√°tico**: Resultados guardados en JSON con numeraci√≥n incremental

## üõ†Ô∏è Instalaci√≥n

### Prerrequisitos

- Python 3.7 o superior
- [Ollama](https://ollama.ai/) instalado y corriendo
- Modelo Qwen2.5-VL descargado: `ollama pull qwen2.5vl:latest`

### Dependencias Python

```bash
pip install -r requirements.txt
```

O instalar manualmente:

```bash
pip install doctr requests python-doctr[torch]
```

### Configuraci√≥n de Ollama

1. Instala [Ollama](https://ollama.ai/)
2. Inicia el servicio: `ollama serve`
3. Descarga el modelo: `ollama pull qwen2.5vl:latest`

## üöÄ Uso R√°pido

### Uso B√°sico

```python
from ocr_pipeline import OCRPipeline

# Inicializar el pipeline
pipeline = OCRPipeline()

# Procesar un documento (solo im√°genes actualmente)
results = pipeline.process_document("documento.jpg", tasks=["clean", "extract"])

# Guardar resultados
pipeline.save_results(results, "resultado.json")
```

### Modos de Procesamiento Disponibles

1. **"clean"**: Corrige errores del OCR bas√°ndose en an√°lisis visual
2. **"extract"**: Extrae informaci√≥n clave en formato JSON
3. **"structure"**: Estructura el contenido en JSON organizado
4. **"summarize"**: Genera un resumen en formato markdown

### Ejemplo Completo

```python
# Inicializar con configuraci√≥n personalizada
pipeline = OCRPipeline(
    ollama_url="http://localhost:11434",
    model_name="qwen2.5vl:latest"
)

# Procesar con m√∫ltiples tareas
tasks = ["clean", "extract", "summarize"]
results = pipeline.process_document("factura.jpg", tasks)  # Solo im√°genes soportadas actualmente

# Los resultados incluyen:
# - results["ocr_raw"]: Resultado original del docTR
# - results["ai_clean"]: Texto corregido por la IA
# - results["ai_extract"]: Datos estructurados en JSON
# - results["ai_summarize"]: Resumen en markdown
```

## üìã Estructura de Resultados

El sistema devuelve un diccionario con la siguiente estructura:

```json
{
  "ocr_raw": {
    "raw_text": "Texto extra√≠do por docTR",
    "structured_data": {...},
    "confidence": 0.95
  },
  "ai_clean": "Texto corregido y mejorado",
  "ai_extract": [{"campo": "valor", "dato": "informaci√≥n"}],
  "ai_summarize": "# Documento\n\n## Contenido\n\nTexto estructurado en markdown"
}
```

## üîß Configuraci√≥n Avanzada

### Cambiar Modelo VLM

```python
# Usar otro modelo compatible
pipeline = OCRPipeline(model_name="llava:latest")
```

### Configurar Ollama Remoto

```python
# Conectar a Ollama en otro servidor
pipeline = OCRPipeline(ollama_url="http://192.168.1.100:11434")
```

### Personalizar Prompts

Los prompts est√°n definidos en el m√©todo `process_with_qwen()` y pueden ser modificados para adaptarse a necesidades espec√≠ficas.

## üéØ Casos de Uso

- **Digitalizaci√≥n de Im√°genes**: Convertir im√°genes de documentos a texto digital preciso
- **Procesamiento de Facturas**: Extraer datos estructurados de facturas y recibos (en formato imagen)
- **An√°lisis de Formularios**: Procesar formularios completados manualmente (en formato imagen)
- **Digitalizaci√≥n de P√°ginas**: Convertir p√°ginas de libros a texto editable (en formato imagen)
- **Procesamiento de Documentos**: Extraer informaci√≥n clave de documentos (en formato imagen)

## üîÆ Roadmap Futuro

- [ ] **Soporte para PDF**: Procesamiento de documentos PDF
- [ ] Integraci√≥n con APIs de modelos comerciales (OpenAI, Claude, etc.)
- [ ] Interfaz web para facilitar el uso
- [ ] Soporte para procesamiento por lotes
- [ ] Integraci√≥n con bases de datos
- [ ] Modo de procesamiento as√≠ncrono
- [ ] Soporte para m√°s modelos VLM

## üêõ Soluci√≥n de Problemas

### Problemas Comunes

1. **Error de conexi√≥n con Ollama**
   - Aseg√∫rate de que Ollama est√© corriendo: `ollama serve`
   - Verifica que el modelo est√© descargado: `ollama list`

2. **Problemas de codificaci√≥n en Windows**
   - El script incluye configuraci√≥n autom√°tica de UTF-8 para Windows
   - Si persisten problemas, ejecuta `chcp 65001` en la terminal

3. **Baja precisi√≥n en el OCR**
   - Aseg√∫rate de que las im√°genes tengan buena calidad
   - Considera preprocesar las im√°genes (mejorar contraste, resoluci√≥n)

## üìù Requisitos del Sistema

- **Sistema Operativo**: Windows, Linux, macOS
- **Python**: 3.7 o superior
- **Memoria RAM**: M√≠nimo 4GB (recomendado 8GB+ para modelos grandes)
- **Almacenamiento**: 2GB para modelos de Ollama
- **GPU**: Opcional, pero recomendada para procesamiento m√°s r√°pido

## ü§ù Contribuciones

¬°Las contribuciones son bienvenidas! Por favor:

1. Fork este repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregando nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto es de c√≥digo abierto. Si deseas utilizarlo, modificarlo o contribuir, si√©ntete libre de hacerlo. Para m√°s informaci√≥n sobre licenciamiento, puedes contactar al maintainer.

## üôè Agradecimientos

- **[docTR](https://github.com/mindee/doctr)** - Excelente librer√≠a de OCR
- **[Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL)** - Modelo de visi√≥n utilizado
- **[Ollama](https://ollama.ai/)** - Plataforma para ejecutar modelos localmente

## üìû Contacto

Para preguntas, sugerencias o reporte de issues:

- Crea un [issue](https://github.com/Leythertv/DOCTR/issues) en este repositorio
- Contacta al maintainer: Leythertv

---

**DOCTR** - Transformando documentos en conocimiento preciso y estructurado üöÄ